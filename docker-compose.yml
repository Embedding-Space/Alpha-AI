services:
  alpha-ai:
    build: .
    container_name: alpha-ai
    ports:
      - "8100:8000"  # Using 8100 externally, 48765 internally
    environment:
      - MODEL=${MODEL:?MODEL environment variable is required}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434/v1}
      - MCP_CONFIG_FILE=${MCP_CONFIG_FILE:-/app/mcp_config.json}
      - STREAMING=${STREAMING:-1}
    volumes:
      - alpha-ai-data:/data
      - ./mcp_config.json:/app/mcp_config.json:ro
      - ./system_prompt.md:/app/system_prompt.md:ro
      - ./models.json:/app/models.json:ro
      - npm-cache:/root/.npm
      - uv-cache:/root/.cache/uv
    networks:
      - alpha-network
    restart: unless-stopped

volumes:
  alpha-ai-data:
  npm-cache:
  uv-cache:

networks:
  alpha-network:
    driver: bridge
